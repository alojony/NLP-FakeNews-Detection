{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2355d756-512d-4da8-b35e-d7bb0e1e7bc8",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87bff4f-754e-403d-809e-c8e07da54ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/xavier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2024-03-28 16:36:17.114153: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-28 16:36:19.060929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 16:36:22.090962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from modules.preprocess import *\n",
    "from modules.utils import build_dataset, text_to_word2vec, evaluate\n",
    "from modules.rnn_model import TextRNN\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931f1e8-cf5e-4f82-a0f6-c6e67f5ae0c0",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7342834-aff0-4144-9cc5-1a3f35161a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset('archive/truth_seeker.xlsx', num_class_samples=-1, rnd_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf0b2ef-eb5d-4d95-8b87-f8fba4f7df70",
   "metadata": {},
   "source": [
    "### PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9e22a5-9d44-45f6-a8f3-6ad15530c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = text_edit(dataset,\n",
    "                    grp_num=False,\n",
    "                    rm_newline=True,\n",
    "                    rm_punctuation=True,\n",
    "                    rm_stop_words=False,\n",
    "                    lowercase=True,\n",
    "                    lemmatize=False,\n",
    "                    expand=False,\n",
    "                    html_=True,\n",
    "                    symb_to_text=False,\n",
    "                    convert_entities=False,\n",
    "                    reduce_mentions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199a9d7-fdd1-41c0-bffd-8871a822e58d",
   "metadata": {},
   "source": [
    "### CREATE SAMPLE AND TARGET LISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6add6bfe-5a40-4f1e-8e9e-61a1c77e31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x['tweet'] for x in dataset.values()]\n",
    "Y = [x['BinaryNumTarget'] for x in dataset.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199fc6cb-9a8d-4cc9-9012-ce6c306f5960",
   "metadata": {},
   "source": [
    "### TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96fa22b5-5a5d-4248-85a5-228ddcc62d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be4d42-37df-4889-93aa-cdb00abd421e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac5a35d-15d3-4747-adad-04601b390803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'fasttext-wiki-news-subwords-300'\n",
    "word2vec_model = api.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1512f809-cb66-4be8-90f6-c42d6ea7f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Ceci est un texte exemple\"\n",
    "vector = text_to_word2vec(text, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7edef08-5256-42a4-a5cd-6bb00e3b2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vector.shape[0]  \n",
    "hidden_size = 128\n",
    "output_size = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8152dad-3fec-4c70-bc84-f1db4b2caa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextRNN(input_size, hidden_size, output_size, batch_first=True, nonlinearity='relu', dropout=0, bidirectional=True, num_layers=1)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "422dfb74-9c59-4546-8454-5de0f22bbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.stack([torch.tensor(text_to_word2vec(x, word2vec_model), dtype=torch.float32).view(1,-1) for x in X_train], dim=0)\n",
    "X_test = torch.stack([torch.tensor(text_to_word2vec(x, word2vec_model), dtype=torch.float32).view(1,-1) for x in X_test], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd5cf5c-2ffe-441a-ba7d-9a22047d1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c6e9e-3b7e-4d5c-a17c-5c34341ef140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd66eba-e1af-4913-9f39-6882d6e9b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "test_writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ed45c7-05c3-43ec-8bb3-19ade0156fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for epoch 0:\n",
      "Mean train loss for epoch: 0.43203526735305786\n",
      "Mean test loss for epoch: 0.3752400577068329\n",
      "Model saved at epoch 0 with test loss 0.3752400577068329\n",
      "Results for epoch 1:\n",
      "Mean train loss for epoch: 0.3340316712856293\n",
      "Mean test loss for epoch: 0.30630311369895935\n",
      "Model saved at epoch 1 with test loss 0.30630311369895935\n",
      "Results for epoch 2:\n",
      "Mean train loss for epoch: 0.28202348947525024\n",
      "Mean test loss for epoch: 0.28220826387405396\n",
      "Model saved at epoch 2 with test loss 0.28220826387405396\n",
      "Results for epoch 3:\n",
      "Mean train loss for epoch: 0.2536272704601288\n",
      "Mean test loss for epoch: 0.24460996687412262\n",
      "Model saved at epoch 3 with test loss 0.24460996687412262\n",
      "Results for epoch 4:\n",
      "Mean train loss for epoch: 0.23049144446849823\n",
      "Mean test loss for epoch: 0.22559095919132233\n",
      "Model saved at epoch 4 with test loss 0.22559095919132233\n",
      "Results for epoch 5:\n",
      "Mean train loss for epoch: 0.21539407968521118\n",
      "Mean test loss for epoch: 0.22569037973880768\n",
      "Results for epoch 6:\n",
      "Mean train loss for epoch: 0.2022799700498581\n",
      "Mean test loss for epoch: 0.2485547512769699\n",
      "Results for epoch 7:\n",
      "Mean train loss for epoch: 0.19207587838172913\n",
      "Mean test loss for epoch: 0.21176856756210327\n",
      "Model saved at epoch 7 with test loss 0.21176856756210327\n",
      "Results for epoch 8:\n",
      "Mean train loss for epoch: 0.18252445757389069\n",
      "Mean test loss for epoch: 0.22729061543941498\n",
      "Results for epoch 9:\n",
      "Mean train loss for epoch: 0.17596040666103363\n",
      "Mean test loss for epoch: 0.19766175746917725\n",
      "Model saved at epoch 9 with test loss 0.19766175746917725\n",
      "Results for epoch 10:\n",
      "Mean train loss for epoch: 0.17085805535316467\n",
      "Mean test loss for epoch: 0.19952374696731567\n",
      "Results for epoch 11:\n",
      "Mean train loss for epoch: 0.1635262370109558\n",
      "Mean test loss for epoch: 0.20630228519439697\n",
      "Results for epoch 12:\n",
      "Mean train loss for epoch: 0.158798947930336\n",
      "Mean test loss for epoch: 0.21113285422325134\n",
      "Results for epoch 13:\n",
      "Mean train loss for epoch: 0.1527193933725357\n",
      "Mean test loss for epoch: 0.2102842479944229\n",
      "Results for epoch 14:\n",
      "Mean train loss for epoch: 0.15015307068824768\n",
      "Mean test loss for epoch: 0.18589472770690918\n",
      "Model saved at epoch 14 with test loss 0.18589472770690918\n",
      "Results for epoch 15:\n",
      "Mean train loss for epoch: 0.14451763033866882\n",
      "Mean test loss for epoch: 0.19838674366474152\n",
      "Results for epoch 16:\n",
      "Mean train loss for epoch: 0.14229701459407806\n",
      "Mean test loss for epoch: 0.20373055338859558\n",
      "Results for epoch 17:\n",
      "Mean train loss for epoch: 0.1403881311416626\n",
      "Mean test loss for epoch: 0.19432763755321503\n",
      "Results for epoch 18:\n",
      "Mean train loss for epoch: 0.13635094463825226\n",
      "Mean test loss for epoch: 0.19035369157791138\n",
      "Results for epoch 19:\n",
      "Mean train loss for epoch: 0.13319934904575348\n",
      "Mean test loss for epoch: 0.19161789119243622\n",
      "Results for epoch 20:\n",
      "Mean train loss for epoch: 0.13134099543094635\n",
      "Mean test loss for epoch: 0.20177994668483734\n",
      "Results for epoch 21:\n",
      "Mean train loss for epoch: 0.12736430764198303\n",
      "Mean test loss for epoch: 0.18533048033714294\n",
      "Model saved at epoch 21 with test loss 0.18533048033714294\n",
      "Results for epoch 22:\n",
      "Mean train loss for epoch: 0.12426646053791046\n",
      "Mean test loss for epoch: 0.22083309292793274\n",
      "Results for epoch 23:\n",
      "Mean train loss for epoch: 0.12305720150470734\n",
      "Mean test loss for epoch: 0.19709059596061707\n",
      "Results for epoch 24:\n",
      "Mean train loss for epoch: 0.12061111629009247\n",
      "Mean test loss for epoch: 0.19849947094917297\n",
      "Results for epoch 25:\n",
      "Mean train loss for epoch: 0.11858455836772919\n",
      "Mean test loss for epoch: 0.2203490436077118\n",
      "Results for epoch 26:\n",
      "Mean train loss for epoch: 0.11593611538410187\n",
      "Mean test loss for epoch: 0.19274264574050903\n",
      "Results for epoch 27:\n",
      "Mean train loss for epoch: 0.11552190035581589\n",
      "Mean test loss for epoch: 0.19553479552268982\n",
      "Results for epoch 28:\n",
      "Mean train loss for epoch: 0.11325885355472565\n",
      "Mean test loss for epoch: 0.18874378502368927\n",
      "Results for epoch 29:\n",
      "Mean train loss for epoch: 0.11224864423274994\n",
      "Mean test loss for epoch: 0.20924599468708038\n",
      "Results for epoch 30:\n",
      "Mean train loss for epoch: 0.1098935678601265\n",
      "Mean test loss for epoch: 0.20710183680057526\n",
      "Results for epoch 31:\n",
      "Mean train loss for epoch: 0.10632267594337463\n",
      "Mean test loss for epoch: 0.19149772822856903\n",
      "Stopping early at epoch 31 due to no improvement in test loss for 5 consecutive epochs.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "epochs_without_improvement = 0  \n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for X, Y in dataloader:  \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X).view(-1)\n",
    "        loss = criterion(outputs, Y)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.detach())\n",
    "    for X, Y in test_dataloader:  \n",
    "        model.eval()\n",
    "        outputs = model(X).view(-1)\n",
    "        loss = criterion(outputs, Y)\n",
    "        writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "        test_losses.append(loss.detach())\n",
    "\n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "    print(f'Results for epoch {epoch}:')\n",
    "    print(f'Mean train loss for epoch: {np.mean(train_losses)}')\n",
    "    print(f'Mean test loss for epoch: {mean_test_loss}')\n",
    "\n",
    "    if mean_test_loss < best_test_loss:\n",
    "        best_test_loss = mean_test_loss\n",
    "        epochs_without_improvement = 0  \n",
    "        torch.save(model.state_dict(), 'rnn_best.pt') \n",
    "        print(f'Model saved at epoch {epoch} with test loss {mean_test_loss}')\n",
    "    else:\n",
    "        epochs_without_improvement += 1  \n",
    "\n",
    "    if epochs_without_improvement >= 10:\n",
    "        print(f'Stopping early at epoch {epoch} due to no improvement in test loss for 5 consecutive epochs.')\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76c64be7-2471-4f5b-b320-79014fcd2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "test_writer.flush()\n",
    "writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d8b63-2cc6-4a6b-958e-361abecbb720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80019b-f581-4a20-bb2d-a3fd23f817ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d99a233-c8f4-4cbe-a6f5-2a122cde3816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TextRNN(input_size, hidden_size, output_size, batch_first=True, nonlinearity='relu', dropout=0, bidirectional=True, num_layers=1).to(device)\n",
    "state_dict = torch.load('rnn_best.pt', map_location=device)  \n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7e6200c-8a22-4553-9747-f64cf0cc8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_outputs = []\n",
    "for tensor_ in X_test:\n",
    "    output = model(tensor_.view(1,1,-1)).view(-1)\n",
    "    pred_outputs.append(output)\n",
    "pred_outputs = [1 if x > 0.5 else 0 for x in pred_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1180b59-e407-475b-b1ee-f17bcf92431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.93095735162541\n",
      "Recall:  0.9395505167051269\n",
      "F1_score:  0.9352341955457905\n",
      "accuracy:  0.9326950520225215\n"
     ]
    }
   ],
   "source": [
    "evaluate(Y_test.numpy(), pred_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe73d6-da34-42d4-8f9a-50dd2bd57ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c6eb4-6663-4278-b4d4-4f236c01c8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af52b5-add8-46c1-953b-cf30eea7c478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23027ff9-9e59-436c-9248-54f4255c4454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b48aabb9-dc1a-40f0-aa1e-ac1e038d7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9b974e5-5d0f-4c83-a030-5001ee2b0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir=runs --port=6044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a2680-d9e1-4422-b569-360eb16d0842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
